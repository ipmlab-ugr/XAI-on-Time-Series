{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipmlab-ugr/XAI-on-Time-Series/blob/main/Attention_CNN_1D_Corrugation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Deep Learning Model for Time Series Prediction with Attention Mechanism\n",
        "\n",
        "This script implements a convolutional neural network with attention mechanism\n",
        "for time series prediction. It includes data loading, preprocessing, model training,\n",
        "and evaluation. The code is written for implementation in Google Colab.\n",
        "\n",
        "Key Features:\n",
        "- Multiple Conv1D layers with attention mechanism\n",
        "- Ensemble modeling approach\n",
        "- Custom Huber loss function\n",
        "- Comprehensive evaluation metrics\n",
        "- Visualization tools\n",
        "\n",
        "Author: [Masoud Haghbin]\n",
        "Date: [4/24/2025]\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (Conv1D, Dropout, Flatten, Dense,\n",
        "                                    BatchNormalization, concatenate, Input,\n",
        "                                    Multiply, RepeatVector, Permute)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from tensorflow.keras.losses import Loss\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from scipy.stats import zscore\n",
        "import math\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# ======================\n",
        "# CONFIGURATION\n",
        "# ======================\n",
        "CONFIG = {\n",
        "    'data_path': 'data055-withzero-modified-clusterd-2-2 -6-main - Copy.csv',\n",
        "    'input_columns': [\"X1\", \"X2\", \"X3\"],\n",
        "    'target_column': \"cor10000\",\n",
        "    'window_size': 500,\n",
        "    'test_size': 0.2,\n",
        "    'n_models': 1,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 128,\n",
        "    'validation_split': 0.2,\n",
        "    'early_stopping_patience': 5,\n",
        "    'lr_scheduler_factor': 0.125,\n",
        "    'lr_scheduler_min_lr': 1e-4,\n",
        "    'huber_delta': 0.00001\n",
        "}\n",
        "\n",
        "# ======================\n",
        "# CUSTOM LOSS FUNCTION\n",
        "# ======================\n",
        "def huber_loss(y_true, y_pred, delta=CONFIG['huber_delta']):\n",
        "    \"\"\"\n",
        "    Custom Huber loss function implementation.\n",
        "\n",
        "    Args:\n",
        "        y_true: True values\n",
        "        y_pred: Predicted values\n",
        "        delta: Threshold for transition between quadratic and linear loss\n",
        "\n",
        "    Returns:\n",
        "        Computed Huber loss\n",
        "    \"\"\"\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) <= delta\n",
        "    squared_loss = 0.5 * tf.square(error)\n",
        "    linear_loss = delta * (tf.abs(error) - 0.5 * delta)\n",
        "    loss = tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "# ======================\n",
        "# ATTENTION MECHANISM\n",
        "# ======================\n",
        "def attention_mechanism(inputs):\n",
        "    \"\"\"\n",
        "    Implements an attention mechanism for time series data.\n",
        "\n",
        "    Args:\n",
        "        inputs: Input tensor to apply attention to\n",
        "\n",
        "    Returns:\n",
        "        Tensor with attention applied\n",
        "    \"\"\"\n",
        "    x1 = Dense(100, activation='tanh')(inputs)\n",
        "    x = Dense(1, activation='tanh')(x1)\n",
        "    x = Flatten()(x)\n",
        "    x = tf.keras.layers.Activation('sigmoid')(x)\n",
        "    x = RepeatVector(inputs.shape[2])(x)\n",
        "    x = Permute([2, 1])(x)\n",
        "    multiplied = Multiply()([inputs, x])\n",
        "    return multiplied\n",
        "\n",
        "# ======================\n",
        "# MODEL ARCHITECTURE\n",
        "# ======================\n",
        "def create_model(input_shape):\n",
        "    \"\"\"\n",
        "    Creates the neural network model with attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        input_shape: Shape of the input data\n",
        "\n",
        "    Returns:\n",
        "        Compiled Keras model\n",
        "    \"\"\"\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # First convolutional branch\n",
        "    conv1 = Conv1D(100, 4, activation='elu', padding='same',\n",
        "                  strides=1, kernel_regularizer=l1(0.05))(input_layer)\n",
        "    conv2 = Conv1D(50, 2, activation='elu', padding='same',\n",
        "                  strides=1, kernel_regularizer=l1(0.05))(conv1)\n",
        "    att_vector1 = attention_mechanism(conv2)\n",
        "\n",
        "    # Second convolutional branch\n",
        "    conv3 = Conv1D(5, 2, activation='elu', padding='same', strides=1)(input_layer)\n",
        "    conv4 = Conv1D(5, 2, activation='elu', padding='same', strides=1)(conv3)\n",
        "    att_vector2 = attention_mechanism(conv4)\n",
        "\n",
        "    # Third convolutional branch\n",
        "    conv5 = Conv1D(5, 2, activation='elu', padding='same', strides=1)(input_layer)\n",
        "    conv6 = Conv1D(5, 2, activation='elu', padding='same', strides=1)(conv5)\n",
        "    att_vector3 = attention_mechanism(conv6)\n",
        "\n",
        "    # Fourth convolutional branch\n",
        "    conv7 = Conv1D(5, 2, activation='elu', padding='same', strides=1)(input_layer)\n",
        "    conv8 = Conv1D(5, 2, activation='elu', padding='same', strides=1)(conv7)\n",
        "    att_vector4 = attention_mechanism(conv8)\n",
        "\n",
        "    # Merge all branches\n",
        "    merged_vector = concatenate([att_vector1, att_vector2,\n",
        "                               att_vector3, att_vector4], axis=-1)\n",
        "    flat = Flatten()(merged_vector)\n",
        "    dense1 = Dense(2028, activation='relu')(flat)\n",
        "    dense2 = Dense(1024, activation='linear')(dense1)\n",
        "    output_layer = Dense(1, activation='linear')(dense2)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=\"adam\", loss=huber_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "# ======================\n",
        "# DATA PROCESSING\n",
        "# ======================\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"\n",
        "    Loads and preprocesses the data.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (X_train, X_test, y_train, y_test, scaler)\n",
        "    \"\"\"\n",
        "    # Upload and load data\n",
        "    uploaded = files.upload()\n",
        "    df = pd.read_csv(CONFIG['data_path'], skiprows=1,\n",
        "                    usecols=[0, 1, 2, 3],\n",
        "                    names=[\"X1\", \"X2\", \"X3\", \"cor10000\"])\n",
        "\n",
        "    # Extract features and target\n",
        "    y = df[[CONFIG['target_column']]].values.reshape(-1, 1)\n",
        "    x = df[CONFIG['input_columns']]\n",
        "\n",
        "    # Scale data\n",
        "    scaler_x = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "\n",
        "    x_scaled = scaler_x.fit_transform(x)\n",
        "    y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "    # Create sliding windows\n",
        "    xx = []\n",
        "    yy = []\n",
        "    for i in range(len(x_scaled) - CONFIG['window_size'] + 1):\n",
        "        xx.append(x_scaled[i:i + CONFIG['window_size']])\n",
        "        yy.append(y_scaled[i + CONFIG['window_size'] - 1])\n",
        "\n",
        "    xx = np.array(xx)\n",
        "    yy = np.array(yy).ravel()\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        xx, yy, test_size=CONFIG['test_size'], shuffle=False)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, scaler_y\n",
        "\n",
        "# ======================\n",
        "# MODEL TRAINING\n",
        "# ======================\n",
        "def train_models(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Trains an ensemble of models.\n",
        "\n",
        "    Args:\n",
        "        X_train: Training features\n",
        "        y_train: Training targets\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (trained_models, training_histories)\n",
        "    \"\"\"\n",
        "    ensemble_models = []\n",
        "    histories = []\n",
        "\n",
        "    # Callbacks\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=CONFIG['early_stopping_patience'],\n",
        "        restore_best_weights=True)\n",
        "\n",
        "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=CONFIG['lr_scheduler_factor'],\n",
        "        patience=1,\n",
        "        min_lr=CONFIG['lr_scheduler_min_lr'])\n",
        "\n",
        "    # Train each model\n",
        "    for _ in range(CONFIG['n_models']):\n",
        "        model = create_model((X_train.shape[1], X_train.shape[2]))\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=CONFIG['epochs'],\n",
        "            validation_split=CONFIG['validation_split'],\n",
        "            callbacks=[early_stop, lr_scheduler],\n",
        "            batch_size=CONFIG['batch_size'])\n",
        "\n",
        "        ensemble_models.append(model)\n",
        "        histories.append(history)\n",
        "\n",
        "    return ensemble_models, histories\n",
        "\n",
        "# ======================\n",
        "# EVALUATION\n",
        "# ======================\n",
        "def evaluate_models(models, X_test, y_test, X_train, y_train, scaler):\n",
        "    \"\"\"\n",
        "    Evaluates the trained models and generates predictions.\n",
        "\n",
        "    Args:\n",
        "        models: List of trained models\n",
        "        X_test: Test features\n",
        "        y_test: Test targets\n",
        "        X_train: Train features\n",
        "        y_train: Train targets\n",
        "        scaler: Scaler used for target variable\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results and plots\n",
        "    \"\"\"\n",
        "    # Generate predictions\n",
        "    predictions = [model.predict(X_test) for model in models]\n",
        "    average_predictions = np.mean(predictions, axis=0)\n",
        "\n",
        "    # For plotting\n",
        "    y_pred_train = models[0].predict(X_train)\n",
        "\n",
        "    # Adjust lengths if needed\n",
        "    y_test2 = y_test[:9274]\n",
        "    y_pred_test2 = average_predictions[216:9490]\n",
        "\n",
        "    # Plot results\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(y_pred_test2, color='red', label=\"Predicted\")\n",
        "    plt.plot(y_test2, color='blue', label=\"Observed\", linestyle='--')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Standard Corrugation')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"test2_plot-withlag.pdf\", format=\"pdf\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(y_train, color='blue', linewidth=1, label=\"Observed\")\n",
        "    plt.plot(y_pred_train, color='red', linewidth=1, label=\"Predicted\")\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Standard Corrugation')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"train_plot-withlag.pdf\", format=\"pdf\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate metrics\n",
        "    r2train = r2_score(y_train, y_pred_train)\n",
        "    r2test = r2_score(y_test2, y_pred_test2)\n",
        "    cc_train = math.sqrt(r2train)\n",
        "\n",
        "    print(\"R^2 Score train:\", r2train)\n",
        "    print(\"R^2 Score test:\", r2test)\n",
        "    print(\"Correlation Coefficient score Train:\", cc_train)\n",
        "\n",
        "    # Cross-correlation analysis\n",
        "    plot_cross_correlation(y_test2, y_pred_test2, \"Test\")\n",
        "    plot_cross_correlation(y_train, y_pred_train, \"Train\")\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(histories)\n",
        "\n",
        "    # Inverse scaling for original units\n",
        "    results = inverse_scale_predictions(\n",
        "        y_test2, y_pred_test2, y_train, y_pred_train, scaler)\n",
        "\n",
        "    return results\n",
        "\n",
        "def plot_cross_correlation(observed, predicted, dataset_name):\n",
        "    \"\"\"\n",
        "    Plots cross-correlation between observed and predicted values.\n",
        "    \"\"\"\n",
        "    observed = observed.ravel()\n",
        "    predicted = predicted.ravel()\n",
        "\n",
        "    lags = np.arange(-len(predicted) + 1, len(observed))\n",
        "    ccf = np.correlate(predicted - predicted.mean(),\n",
        "                      observed - observed.mean(),\n",
        "                      mode='full')\n",
        "    ccf /= (np.std(predicted) * np.std(observed) * len(predicted))\n",
        "\n",
        "    lag_max_corr = lags[np.argmax(ccf)]\n",
        "\n",
        "    plt.plot(lags, ccf)\n",
        "    plt.xlabel('Lag')\n",
        "    plt.ylabel('Cross-Correlation')\n",
        "    plt.title(f'{dataset_name} - Max Correlation at Lag {lag_max_corr}')\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_history(histories):\n",
        "    \"\"\"\n",
        "    Plots training and validation loss for each model.\n",
        "    \"\"\"\n",
        "    for i, history in enumerate(histories):\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(history.history['loss'], label='Train Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title(f'Model {i+1} Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.yscale('log')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "def inverse_scale_predictions(y_test, y_pred_test, y_train, y_pred_train, scaler):\n",
        "    \"\"\"\n",
        "    Inverse transforms predictions to original scale and calculates metrics.\n",
        "    \"\"\"\n",
        "    # Reshape arrays\n",
        "    y_pred_test_reshaped = y_pred_test.reshape(-1, 1)\n",
        "    y_test_reshaped = y_test.reshape(-1, 1)\n",
        "    y_pred_train_reshaped = y_pred_train.reshape(-1, 1)\n",
        "    y_train_reshaped = y_train.reshape(-1, 1)\n",
        "\n",
        "    # Inverse transform divided by 10000 to hav real values\n",
        "    y_pred_test_inversed = scaler.inverse_transform(y_pred_test_reshaped) / 10000\n",
        "    y_test_inversed = scaler.inverse_transform(y_test_reshaped) / 10000\n",
        "    y_pred_train_inversed = scaler.inverse_transform(y_pred_train_reshaped)/10000\n",
        "    y_train_inversed = scaler.inverse_transform(y_train_reshaped)/10000\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(y_test_inversed, label='Actual')\n",
        "    plt.plot(y_pred_test_inversed, label='Predicted', linestyle='--')\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('Value')\n",
        "    plt.title('Predicted vs Actual Values (Original Scale)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse_test = np.mean((y_test_inversed - y_pred_test_inversed) ** 2)\n",
        "    mse_train = np.mean((y_train_inversed - y_pred_train_inversed) ** 2)\n",
        "    r2_test = r2_score(y_test_inversed/1, y_pred_test_inversed/1)\n",
        "\n",
        "    print(\"Mean Squared Error (MSE) Test:\", mse_test)\n",
        "    print(\"Mean Squared Error (MSE) Train:\", mse_train)\n",
        "\n",
        "\n",
        "    return {\n",
        "        'y_test_inversed': y_test_inversed,\n",
        "        'y_pred_test_inversed': y_pred_test_inversed,\n",
        "        'y_train_inversed': y_train_inversed,\n",
        "        'y_pred_train_inversed': y_pred_train_inversed,\n",
        "        'mse_test': mse_test,\n",
        "        'mse_train': mse_train,\n",
        "        'r2_test': r2_test\n",
        "    }\n",
        "\n",
        "# ======================\n",
        "# RESULTS EXPORT\n",
        "# ======================\n",
        "def export_results(results):\n",
        "    \"\"\"\n",
        "    Exports results to CSV and Excel files.\n",
        "    \"\"\"\n",
        "    # Install required package\n",
        "    !pip install -q XlsxWriter\n",
        "\n",
        "    # Test results\n",
        "    results_df_test = pd.DataFrame({\n",
        "        'Observed_Test_inversed': results['y_test_inversed'].ravel() / 10000,\n",
        "        'Predicted_Test_inversed': results['y_pred_test_inversed'].ravel() / 10000,\n",
        "    })\n",
        "\n",
        "    # Train results\n",
        "    results_df_train = pd.DataFrame({\n",
        "        'Observed_Train_inversed': results['y_train_inversed'].ravel() / 10000,\n",
        "        'Predicted_Train_inversed': results['y_pred_train_inversed'].ravel() / 10000,\n",
        "    })\n",
        "\n",
        "    # Save to CSV\n",
        "    test_results_csv = 'final-results-with-zero-SC1-test-stage-05-for-thesis-9-26-2024-final-unsupervised.csv'\n",
        "    train_results_csv = 'final-results-with-zero-SC1-train-stage-05-for-thesis-9-26-2024-final-unsupervised.csv'\n",
        "\n",
        "    results_df_test.to_csv(test_results_csv, index=False)\n",
        "    results_df_train.to_csv(train_results_csv, index=False)\n",
        "\n",
        "    # Save training history to Excel\n",
        "    excel_writer = pd.ExcelWriter(\n",
        "        '/content/final-all_loss_data-combo-modified-05-for-thesis-9-26-2024-final.xlsx',\n",
        "        engine='xlsxwriter')\n",
        "\n",
        "    for i, history in enumerate(histories):\n",
        "        data_dict = {\n",
        "            'Epochs': list(range(1, len(history.history['loss']) + 1)),\n",
        "            'Train_Loss': history.history['loss'],\n",
        "            'Validation_Loss': history.history['val_loss']\n",
        "        }\n",
        "        df = pd.DataFrame(data_dict)\n",
        "        sheet_name = f'Model_{i+1}'\n",
        "        df.to_excel(excel_writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    excel_writer.close()\n",
        "\n",
        "    # Download files\n",
        "    files.download(test_results_csv)\n",
        "    files.download(train_results_csv)\n",
        "    files.download('/content/final-all_loss_data-combo-modified-05-for-thesis-9-26-2024-final.xlsx')\n",
        "\n",
        "# ======================\n",
        "# MAIN EXECUTION\n",
        "# ======================\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    X_train, X_test, y_train, y_test, scaler_y = load_and_preprocess_data()\n",
        "\n",
        "    # Train models\n",
        "    ensemble_models, histories = train_models(X_train, y_train)\n",
        "\n",
        "    # Evaluate models\n",
        "    results = evaluate_models(\n",
        "        ensemble_models, X_test, y_test,\n",
        "        X_train, y_train, scaler_y)\n",
        "\n",
        "    # Export results\n",
        "    export_results(results)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SEpYSMnShHEf",
        "outputId": "df906757-0e9c-4b94-ae80-d3e25b71140a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0da50768791e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# --- Step 5: Example usage on test data ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mtarget_layer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_last_conv1d_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0mtest_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradcam_to_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_layer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mplot_heatmaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_heatmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Test Sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Step 1: Identify the last Conv1D layer in the model ---\n",
        "def get_last_conv1d_layer(model):\n",
        "    \"\"\"\n",
        "    Returns the name of the last Conv1D layer in the given model.\n",
        "\n",
        "    Args:\n",
        "        model: A compiled Keras model instance.\n",
        "\n",
        "    Returns:\n",
        "        Name of the last Conv1D layer or None if not found.\n",
        "    \"\"\"\n",
        "    for layer in reversed(model.layers):\n",
        "        if isinstance(layer, keras.layers.Conv1D):\n",
        "            return layer.name\n",
        "    return None\n",
        "\n",
        "# --- Step 2: Define the Grad-CAM function for 1D data ---\n",
        "def apply_gradcam_to_predictions(model, X_data, target_layer_name):\n",
        "    \"\"\"\n",
        "    Applies Grad-CAM to each sample in X_data using the specified Conv1D layer.\n",
        "\n",
        "    Parameters:\n",
        "        model (keras.Model): Trained Keras model.\n",
        "        X_data (np.ndarray): Input samples (3D array: [samples, timesteps, features]).\n",
        "        target_layer_name (str): Name of the Conv1D layer to compute Grad-CAM on.\n",
        "\n",
        "    Returns:\n",
        "        List of heatmaps (one per sample).\n",
        "    \"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(target_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    heatmaps = []\n",
        "\n",
        "    for sample in X_data:\n",
        "        sample = np.expand_dims(sample, axis=0)  # Add batch dimension\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            conv_output, prediction = grad_model(sample)\n",
        "            target_output = prediction[0]  # Single output for regression/classification\n",
        "\n",
        "        # Compute gradients of the output with respect to the conv layer output\n",
        "        grads = tape.gradient(target_output, conv_output)\n",
        "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1))  # Global average pooling\n",
        "\n",
        "        # Weight the conv output channels by importance\n",
        "        conv_output = conv_output[0]\n",
        "        weighted_output = conv_output @ pooled_grads[..., tf.newaxis]\n",
        "        heatmap = tf.squeeze(weighted_output)\n",
        "\n",
        "        # Normalize the heatmap\n",
        "        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-6)\n",
        "        heatmaps.append(heatmap.numpy())\n",
        "\n",
        "    return heatmaps\n",
        "\n",
        "# --- Step 3: Visualize heatmaps for a few test samples ---\n",
        "#def plot_heatmaps(heatmaps, num_samples=3, title_prefix=\"Sample\"):\n",
        "   # for i, heatmap in enumerate(heatmaps[:num_samples]):\n",
        "   #     plt.figure()\n",
        "     #  plt.plot(heatmap)\n",
        "      #  plt.xlabel(\"Steps\")\n",
        "      #  plt.ylabel(\"Activation Intensity\")\n",
        "      #  plt.title(f\"{title_prefix} {i + 1}\")\n",
        "       # plt.tight_layout()\n",
        "      #  plt.show()\n",
        "\n",
        "# --- Step 4: Compute and plot the average heatmap ---\n",
        "#def plot_average_heatmap(heatmaps, title=\"Average Heatmap\"):\n",
        "  #  heatmap_array = np.array(heatmaps)\n",
        "   # average_heatmap = np.mean(heatmap_array, axis=0)\n",
        "\n",
        "   # plt.figure()\n",
        "  #  plt.plot(average_heatmap)\n",
        "  #  plt.xlabel(\"Steps\")\n",
        "  #  plt.ylabel(\"Average Activation Intensity\")\n",
        "   # plt.title(title)\n",
        "  #  plt.tight_layout()\n",
        "  #  plt.show()\n",
        "\n",
        "# --- Step 5: Example usage on test data ---\n",
        "model = ensemble_models[0]  # pick one model from the ensemble\n",
        "target_layer_name = get_last_conv1d_layer(model)\n",
        "test_heatmaps = apply_gradcam_to_predictions(model, X_test, target_layer_name)\n",
        "# --- Optional: Compute average intensity per heatmap ---\n",
        "average_intensities = [np.mean(hm) for hm in test_heatmaps]\n",
        "\n",
        "# Convert average intensities to a 2D array (1 row, N columns)\n",
        "average_intensities_array = np.array(average_intensities)[np.newaxis, :]\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.imshow(average_intensities_array, cmap='viridis', aspect='auto')\n",
        "plt.colorbar(label='Average Intensity')\n",
        "plt.xlabel(\"Heatmap Index\")\n",
        "plt.yticks([])  # Hide y-axis ticks (optional)\n",
        "plt.title(\"Average Intensity per Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Step 6: Example usage on training data ---\n",
        "train_heatmaps = apply_gradcam_to_predictions(model, X_train, target_layer_name)\n",
        "average_intensities_train = [np.mean(hm) for hm in train_heatmaps]\n",
        "average_intensities_array_train = np.array(average_intensities_train)[np.newaxis, :]\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.imshow(average_intensities_array_train, cmap='viridis', aspect='auto')\n",
        "plt.colorbar(label='Average Intensity')\n",
        "plt.xlabel(\"Heatmap Index\")\n",
        "plt.yticks([])  # Hide y-axis ticks (optional)\n",
        "plt.title(\"Average Intensity per Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "H7sr4eqv279X",
        "outputId": "41c6dc8d-efec-46ec-d9df-da1a1cd04ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: [['keras_tensor_84']]\n",
            "Received: inputs=Tensor(shape=(1, 500, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNWCmLkACaf0ZbIv29QNbJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}